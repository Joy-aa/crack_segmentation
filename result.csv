datetime,modelType,trainLoss,validLoss,Accuracy,Precision,Recall,F1-score,MIOU
2023-05-11 12:05:33.141895,./checkpoints/Unet++_10.pth,"tensor(0.0277, device='cuda:0', requires_grad=True)",0.034832802906789334,0.9598266228641138,0.0,0.0,nan,0.0037713298704133654
2023-05-11 14:40:25.220001,./checkpoints/Unet++_10.pth,"tensor(0.0277, device='cuda:0', requires_grad=True)",0.034832802906789334,0,0,0,0,0
2023-05-11 15:01:57.836966,./checkpoints/Unet++_10.pth,"tensor(0.0277, device='cuda:0', requires_grad=True)",0.034832802906789334,0,0,0,0,0
{'accuracy': 0.9927020175834901, 'neg_accuracy': 0.9954583474168487, 'precision': 0.34330293662336203, 'recall': 0.602664553531804, 'f1': 0.4149748666688159}, 
{'accuracy': 0.9929985590517214, 'neg_accuracy': 0.9957904736551856, 'precision': 0.3528288284818981, 'recall': 0.5853935708194087, 'f1': 0.4173734310381155}, 
{'accuracy': 0.9931749695229303, 'neg_accuracy': 0.9959976598855497, 'precision': 0.3588822527640144, 'recall': 0.5736155923917432, 'f1': 0.41830782368243635}, 
{'accuracy': 0.9933127227744908, 'neg_accuracy': 0.9961752888797419, 'precision': 0.3638205862062336, 'recall': 0.5632515565521132, 'f1': 0.4186248486928522}, 
{'accuracy': 0.9934282086134568, 'neg_accuracy': 0.9963363781966883, 'precision': 0.36818502164159517, 'recall': 0.5532538678237183, 'f1': 0.41846989295481396}, 
{'accuracy': 0.9935386427660864, 'neg_accuracy': 0.9965061538189508, 'precision': 0.3723866814951934, 'recall': 0.5420002284142114, 'f1': 0.417568911579863}, 
{'accuracy': 0.9936420168435521, 'neg_accuracy': 0.9966685044350252, 'precision': 0.37647519441103844, 'recall': 0.5299407296948405, 'f1': 0.41604172628889036}, 
{'accuracy': 0.9937535003530015, 'neg_accuracy': 0.9968671471486537, 'precision': 0.3809169272752867, 'recall': 0.5135808152763454, 'f1': 0.4128373227758849}, 
{'accuracy': 0.9938857074745702, 'neg_accuracy': 0.9971398257412922, 'precision': 0.3858719496107711, 'recall': 0.4877225584546837, 'f1': 0.40575629841332117}
